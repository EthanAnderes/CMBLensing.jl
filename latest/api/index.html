<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>API · CMBLensing.jl</title><link href="https://cdnjs.cloudflare.com/ajax/libs/normalize/4.2.0/normalize.min.css" rel="stylesheet" type="text/css"/><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.2.0/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link href="../assets/documenter.css" rel="stylesheet" type="text/css"/><link href="../assets/cmblensing.css" rel="stylesheet" type="text/css"/></head><body><nav class="toc"><h1>CMBLensing.jl</h1><select id="version-selector" onChange="window.location.href=this.value" style="visibility: hidden"></select><form class="search" id="search-form" action="../search/"><input id="search-query" name="q" type="text" placeholder="Search docs"/></form><ul><li><a class="toctext" href="../">CMBLensing.jl</a></li><li><a class="toctext" href="../01_lense_a_map/">Lensing a flat map</a></li><li><a class="toctext" href="../02_posterior/">The Lensing Posterior</a></li><li><a class="toctext" href="../03_joint_MAP_example/">Joint maximum a posteriori estimate</a></li><li><a class="toctext" href="../04_from_python/">Calling from Python</a></li><li><a class="toctext" href="../05_field_basics/">Field Basics</a></li><li class="current"><a class="toctext" href>API</a><ul class="internal"></ul></li></ul></nav><article id="docs"><header><nav><ul><li><a href>API</a></li></ul></nav><hr/><div id="topbar"><span>API</span><a class="fa fa-bars" href="#"></a></div></header><h1><a class="nav-anchor" id="API-1" href="#API-1">API</a></h1><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="CMBLensing.MAP_joint-Tuple{Any}" href="#CMBLensing.MAP_joint-Tuple{Any}"><code>CMBLensing.MAP_joint</code></a> — <span class="docstring-category">Method</span>.</div><div><pre class="language-julia"><code class="language-julia">MAP_joint(ds::DataSet; L=LenseFlow, Nϕ=nothing, quasi_sample=nothing, nsteps=10, Ncg=500, cgtol=1e-1, αtol=1e-5, αmax=0.5, progress=false)</code></pre><p>Compute the maximum a posteri estimate (MAP) from the joint posterior (can also do a quasi-sample). </p><p>The <code>ds</code> argument stores the data and other relevant objects for the dataset being considered. <code>L</code> gives which type of lensing operator to use. </p><p><code>ϕstart</code> can be used to specify the starting point of the minimizer, but this is not necessary and otherwise it will start at ϕ=0. </p><p><code>Nϕ</code> can optionally specify an estimate of the ϕ effective noise, and if provided is used to estimate a Hessian which is used in the ϕ quasi-Newton-Rhapson step. <code>Nϕ=:qe</code> automatically uses the quadratic estimator noise. </p><p>This function can also be used to draw quasi-samples, wherein for the f step, we draw a sample from  P(f|ϕ) instead of maximizing it (ie instead of computing Wiener filter). <code>quasi_sample</code> can be set to an integer seed, in which case each time in the <code>f</code> step we draw a same-seeded sample. If <code>quasi_sample</code> is instead just <code>true</code>, then each iteration in the algorithm draws a different sample so the solution bounces around rather than asymptoting to a maximum. </p><p>The following arguments control the maximiation procedure, and can generally be left at their defaults:</p><ul><li><code>nsteps</code> - The number of iteration steps to do (each iteration updates f then updates ϕ)</li><li><code>Ncg</code> - Maximum number of conjugate gradient steps during the f update</li><li><code>cgtol</code> - Conjugrate gradient tolerance (will stop at cgtol or Ncg, whichever is first)</li><li><code>αtol</code> - Tolerance for the linesearch in the ϕ quasi-Newton-Rhapson step, <code>x′ = x - α*H⁻¹*g</code></li><li><code>αmax</code> - Maximum value for α in the linesearch</li><li><code>progress</code> - Whether to print out conjugate gradient progress.</li></ul><p>Returns a tuple <code>(f, ϕ, tr)</code> where <code>f</code> is the best-fit (or quasi-sample) field, <code>ϕ</code> is the lensing potential, and <code>tr</code> contains info about the run. </p></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="CMBLensing.MAP_marg-Tuple{Any}" href="#CMBLensing.MAP_marg-Tuple{Any}"><code>CMBLensing.MAP_marg</code></a> — <span class="docstring-category">Method</span>.</div><div><pre class="language-julia"><code class="language-julia">MAP_marg( ds; kwargs...)</code></pre><p>Compute the maximum a posteri estimate (MAP) of the marginl posterior.</p></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="CMBLensing.animate-Tuple{Union{AbstractArray{#s109,1}, AbstractArray{#s109,2}} where #s109&lt;:Field}" href="#CMBLensing.animate-Tuple{Union{AbstractArray{#s109,1}, AbstractArray{#s109,2}} where #s109&lt;:Field}"><code>CMBLensing.animate</code></a> — <span class="docstring-category">Method</span>.</div><div><pre class="language-julia"><code class="language-julia">animate(fields::Vector{\&lt;:Vector{\&lt;:Field}}; interval=50, motionblur=false, kwargs...)</code></pre></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="CMBLensing.argmaxf_lnP-Tuple{Field,Any}" href="#CMBLensing.argmaxf_lnP-Tuple{Field,Any}"><code>CMBLensing.argmaxf_lnP</code></a> — <span class="docstring-category">Method</span>.</div><div><pre class="language-julia"><code class="language-julia">argmaxf_lnP(ϕ,                ds::DataSet; kwargs...)
argmaxf_lnP(ϕ, θ::NamedTuple, ds::DataSet; kwargs...)
argmaxf_lnP(Lϕ::LenseOp,      ds::DataSet; kwargs...)</code></pre><p>Computes either the Wiener filter at fixed <span>$\phi$</span>, or a sample from this slice along the posterior.</p><p>Keyword arguments: </p><ul><li>which : <code>:wf</code>, <code>:sample</code>, or <code>fluctuation</code> to compute 1) the Wiener filter, i.e. the best-fit of <span>$\mathcal{P}(f\,|\,\phi,d)$</span>, 2) a sample from <span>$\mathcal{P}(f\,|\,\phi,d)$</span>, or 3) a sample minus the Wiener filter, i.e. the fluctuation on top of the mean.</li><li>guess : starting guess for <code>f</code> for the conjugate gradient solver</li><li>kwargs : all other arguments are passed to <code>conjugate_gradient</code></li></ul></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="CMBLensing.gradhess-Tuple{Any}" href="#CMBLensing.gradhess-Tuple{Any}"><code>CMBLensing.gradhess</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre class="language-julia"><code class="language-julia">gradhess(f)</code></pre><p>Compute the gradient gⁱ = ∇ⁱf, and the hessian, Hⁱⱼ = ∇ⱼ∇ⁱf</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="CMBLensing.lnP" href="#CMBLensing.lnP"><code>CMBLensing.lnP</code></a> — <span class="docstring-category">Function</span>.</div><div><pre class="language-julia"><code class="language-julia">lnP(t, fₜ, ϕₜ,                ds::DataSet, Lϕ=nothing)
lnP(t, fₜ, ϕₜ, θ::NamedTuple, ds::DataSet, Lϕ=nothing)</code></pre><p>Compute the log posterior probability in the joint parameterization as a function of the field, <span>$f_t$</span>, the lensing potential, <span>$\phi_t$</span>, and possibly some cosmological parameters, <span>$\theta$</span>. The subscript <span>$t$</span> can refer to either a &quot;time&quot;, e.g. passing <code>t=0</code> corresponds to the unlensed parametrization and <code>t=1</code> to the lensed one, or can be <code>:mix</code> correpsonding to the mixed parametrization. In all cases, the arguments <code>fₜ</code> and <code>ϕₜ</code> should then be <span>$f$</span> and <span>$\phi$</span> in that particular parametrization.</p><p>If any parameters <span>$\theta$</span> are passed, we also include the three determinant terms to properly normalize the posterior.</p><p>The argument <code>ds</code> should be a <code>DataSet</code> and stores the masks, data, etc... needed to construct the posterior. If <code>Lϕ</code> is provided, it will be used as memory to recache the lensing operator at the specified ϕ.</p></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="CMBLensing.load_sim_dataset-Tuple{}" href="#CMBLensing.load_sim_dataset-Tuple{}"><code>CMBLensing.load_sim_dataset</code></a> — <span class="docstring-category">Method</span>.</div><div><pre class="language-julia"><code class="language-julia">load_sim_dataset</code></pre><p>Create a <code>DataSet</code> object with some simulated data. E.g.</p><pre class="language-julia"><code class="language-julia">@unpack f,ϕ,ds = load_sim_dataset(;
    θpix  = 2,
    Nside = 128,
    use   = :I,
    T     = Float32
);</code></pre></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="CMBLensing.noiseCℓs-Tuple{}" href="#CMBLensing.noiseCℓs-Tuple{}"><code>CMBLensing.noiseCℓs</code></a> — <span class="docstring-category">Method</span>.</div><div><pre class="language-julia"><code class="language-julia">noiseCℓs(;μKarcminT, beamFWHM=0, ℓmax=8000, ℓknee=100, αknee=3)</code></pre><p>Compute the (:TT,:EE,:BB,:TE) noise power spectra given white noise + 1/f. Polarization noise is scaled by <span>$\sqrt{2}$</span> relative to <code>μKarcminT</code>. <code>beamFWHM</code> is in arcmin.</p></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="CMBLensing.pixwin-Tuple{Any,Any}" href="#CMBLensing.pixwin-Tuple{Any,Any}"><code>CMBLensing.pixwin</code></a> — <span class="docstring-category">Method</span>.</div><div><pre class="language-julia"><code class="language-julia">pixwin(θpix, ℓ)</code></pre><p>Returns the pixel window function for square flat-sky pixels of width <code>θpix</code> (in arcmin) evaluated at some <code>ℓ</code>s. This is the scaling of k-modes, the scaling of the power spectrum will be pixwin^2. </p></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="CMBLensing.quadratic_estimate-Union{Tuple{F2}, Tuple{F1}, Tuple{Tuple{DataSet{F1,TCn,TCf,TCf̃,TCϕ,TCn̂,TM,TM̂,TB,TB̂,TD,TG,TP,TL} where TL where TP where TG where TD where TB̂ where TB where TM̂ where TM where TCn̂ where TCϕ where TCf̃ where TCf where TCn,DataSet{F2,TCn,TCf,TCf̃,TCϕ,TCn̂,TM,TM̂,TB,TB̂,TD,TG,TP,TL} where TL where TP where TG where TD where TB̂ where TB where TM̂ where TM where TCn̂ where TCϕ where TCf̃ where TCf where TCn},Any}} where F2 where F1" href="#CMBLensing.quadratic_estimate-Union{Tuple{F2}, Tuple{F1}, Tuple{Tuple{DataSet{F1,TCn,TCf,TCf̃,TCϕ,TCn̂,TM,TM̂,TB,TB̂,TD,TG,TP,TL} where TL where TP where TG where TD where TB̂ where TB where TM̂ where TM where TCn̂ where TCϕ where TCf̃ where TCf where TCn,DataSet{F2,TCn,TCf,TCf̃,TCϕ,TCn̂,TM,TM̂,TB,TB̂,TD,TG,TP,TL} where TL where TP where TG where TD where TB̂ where TB where TM̂ where TM where TCn̂ where TCϕ where TCf̃ where TCf where TCn},Any}} where F2 where F1"><code>CMBLensing.quadratic_estimate</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre class="language-julia"><code class="language-julia">quadratic_estimate(ds::DataSet, which; wiener_filtered=true)
quadratic_estimate((ds1::DataSet,ds2::DataSet), which; wiener_filtered=true)</code></pre><p>Compute quadratic estimate of ϕ given data.</p><p>The <code>ds</code> or <code>(ds1,ds2)</code> tuple contain the DataSet object(s) which houses the data and covariances used in the estimate. Note that only the Fourier-diagonal approximations for the beam, mask, and noise,, i.e. <code>ds.B̂</code>, <code>ds.M̂</code>, and <code>ds.Cn̂</code>, are accounted for. To account full operators (if they are not actually Fourier-diagonal), you should compute the impact using Monte Carlo.</p><p>If a tuple is passed in, the result will come from correlating the data from <code>ds1</code> with that from <code>ds2</code>, which can be useful for debugging / isolating various noise terms. </p><p>An optional keyword argument <code>AL</code> can be passed in in case the QE normalization was already computed, in which case it won&#39;t be recomputed during the calculation.</p><p>Returns a NamedTuple <code>(ϕqe, AL, Nϕ)</code> where <code>ϕqe</code> is the (possibly Wiener filtered, depending on <code>wiener_filtered</code> option) quadratic estimate, <code>AL</code> is the normalization (which is already applied to ϕqe, it does not need to be applied again), and <code>Nϕ</code> is the analytic N0 noise bias (Nϕ==AL if using unlensed weights, currently only Nϕ==AL is always returned, no matter the weights)</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="CMBLensing.resimulate-Tuple{DataSet}" href="#CMBLensing.resimulate-Tuple{DataSet}"><code>CMBLensing.resimulate</code></a> — <span class="docstring-category">Method</span>.</div><div><pre class="language-julia"><code class="language-julia">resimulate(ds::DataSet; f=..., ϕ=...)</code></pre><p>Resimulate the data in a given dataset, potentially at a fixed f and/or ϕ (both are resimulated if not provided)</p></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="CMBLensing.sample_joint-Union{Tuple{DataSet{#s164,TCn,TCf,TCf̃,TCϕ,TCn̂,TM,TM̂,TB,TB̂,TD,TG,TP,TL} where TL where TP where TG where TD where TB̂ where TB where TM̂ where TM where TCn̂ where TCϕ where TCf̃ where TCf where TCn where #s164&lt;:(Union{FieldTuple{CMBLensing.BasisTuple{Tuple{Fourier,EBFourier}},NamedTuple{(:I, :P),Tuple{FlatFourier{T,P,M},FieldTuple{EBFourier,NamedTuple{(:E, :B),Tuple{FlatFourier{T,P,M},FlatFourier{T,P,M}}},Complex{P}}}},Complex{P}}, FieldTuple{CMBLensing.BasisTuple{Tuple{Fourier,QUFourier}},NamedTuple{(:I, :P),Tuple{FlatFourier{T,P,M},FieldTuple{QUFourier,NamedTuple{(:Q, :U),Tuple{FlatFourier{T,P,M},FlatFourier{T,P,M}}},Complex{P}}}},Complex{P}}, FieldTuple{CMBLensing.BasisTuple{Tuple{Map,EBMap}},NamedTuple{(:I, :P),Tuple{FlatMap{T,P,M},FieldTuple{EBMap,NamedTuple{(:E, :B),Tuple{FlatMap{T,P,M},FlatMap{T,P,M}}},P}}},P}, FieldTuple{CMBLensing.BasisTuple{Tuple{Map,QUMap}},NamedTuple{(:I, :P),Tuple{FlatMap{T,P,M},FieldTuple{QUMap,NamedTuple{(:Q, :U),Tuple{FlatMap{T,P,M},FlatMap{T,P,M}}},P}}},P}, FieldTuple{EBFourier,NamedTuple{(:E, :B),Tuple{FlatFourier{T,P,M},FlatFourier{T,P,M}}},Complex{P}}, FieldTuple{EBMap,NamedTuple{(:E, :B),Tuple{FlatMap{T,P,M},FlatMap{T,P,M}}},P}, FieldTuple{QUFourier,NamedTuple{(:Q, :U),Tuple{FlatFourier{T,P,M},FlatFourier{T,P,M}}},Complex{P}}, FieldTuple{QUMap,NamedTuple{(:Q, :U),Tuple{FlatMap{T,P,M},FlatMap{T,P,M}}},P}, FlatFourier{T,P,M}, FlatMap{T,P,M}} where M)}, Tuple{P}, Tuple{T}} where P where T" href="#CMBLensing.sample_joint-Union{Tuple{DataSet{#s164,TCn,TCf,TCf̃,TCϕ,TCn̂,TM,TM̂,TB,TB̂,TD,TG,TP,TL} where TL where TP where TG where TD where TB̂ where TB where TM̂ where TM where TCn̂ where TCϕ where TCf̃ where TCf where TCn where #s164&lt;:(Union{FieldTuple{CMBLensing.BasisTuple{Tuple{Fourier,EBFourier}},NamedTuple{(:I, :P),Tuple{FlatFourier{T,P,M},FieldTuple{EBFourier,NamedTuple{(:E, :B),Tuple{FlatFourier{T,P,M},FlatFourier{T,P,M}}},Complex{P}}}},Complex{P}}, FieldTuple{CMBLensing.BasisTuple{Tuple{Fourier,QUFourier}},NamedTuple{(:I, :P),Tuple{FlatFourier{T,P,M},FieldTuple{QUFourier,NamedTuple{(:Q, :U),Tuple{FlatFourier{T,P,M},FlatFourier{T,P,M}}},Complex{P}}}},Complex{P}}, FieldTuple{CMBLensing.BasisTuple{Tuple{Map,EBMap}},NamedTuple{(:I, :P),Tuple{FlatMap{T,P,M},FieldTuple{EBMap,NamedTuple{(:E, :B),Tuple{FlatMap{T,P,M},FlatMap{T,P,M}}},P}}},P}, FieldTuple{CMBLensing.BasisTuple{Tuple{Map,QUMap}},NamedTuple{(:I, :P),Tuple{FlatMap{T,P,M},FieldTuple{QUMap,NamedTuple{(:Q, :U),Tuple{FlatMap{T,P,M},FlatMap{T,P,M}}},P}}},P}, FieldTuple{EBFourier,NamedTuple{(:E, :B),Tuple{FlatFourier{T,P,M},FlatFourier{T,P,M}}},Complex{P}}, FieldTuple{EBMap,NamedTuple{(:E, :B),Tuple{FlatMap{T,P,M},FlatMap{T,P,M}}},P}, FieldTuple{QUFourier,NamedTuple{(:Q, :U),Tuple{FlatFourier{T,P,M},FlatFourier{T,P,M}}},Complex{P}}, FieldTuple{QUMap,NamedTuple{(:Q, :U),Tuple{FlatMap{T,P,M},FlatMap{T,P,M}}},P}, FlatFourier{T,P,M}, FlatMap{T,P,M}} where M)}, Tuple{P}, Tuple{T}} where P where T"><code>CMBLensing.sample_joint</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre class="language-julia"><code class="language-julia">sample_joint(ds::DataSet; kwargs...)</code></pre><p>Sample from the joint PDF of P(f,ϕ,θ). Runs <code>nworkers()</code> chains in parallel using <code>pmap</code>. </p><p>Possible keyword arguments: </p><ul><li><code>nsamps_per_chain</code> - the number of samples per chain</li><li><code>nchunk</code> - do <code>nchunk</code> steps in-between parallel chain communication</li><li><code>nsavemaps</code> - save maps into chain every <code>nsavemaps</code> steps</li><li><code>nburnin_always_accept</code> - the first <code>nburnin_always_accept</code> steps, always accept HMC steps independent of integration error</li><li><code>nburnin_fixθ</code> - the first <code>nburnin_fixθ</code> steps, fix θ at its starting point</li><li><code>chains</code> - resume an existing chain (starts a new one if nothing)</li><li><code>θrange</code> - range and density to grid sample parameters as a NamedTuple, e.g. <code>(Aϕ=range(0.7,1.3,length=20),)</code>. </li><li><code>θstart</code> - starting values of parameters as a NamedTuple, e.g. <code>(Aϕ=1.2,)</code>, or nothing to randomly sample from θrange</li><li><code>ϕstart</code> - starting ϕ as a Field, or <code>:quasi_sample</code> or <code>:best_fit</code></li><li><code>metadata</code> - does nothing, but is saved into the chain file</li><li><code>nhmc</code> - the number of HMC passes per ϕ Gibbs step (default: 1)</li></ul></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="CMBLensing.symplectic_integrate-Union{Tuple{T}, Tuple{AbstractArray{T,1},Any,Any,Any,Any}} where T" href="#CMBLensing.symplectic_integrate-Union{Tuple{T}, Tuple{AbstractArray{T,1},Any,Any,Any,Any}} where T"><code>CMBLensing.symplectic_integrate</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre class="language-julia"><code class="language-julia">symplectic_integrate(x₀, p₀, Λ, U, δUδx, N=50, ϵ=0.1, progress=false)</code></pre><p>Do a symplectic integration of the potential energy <code>U</code> (with gradient <code>δUδx</code>) starting from point <code>x₀</code> with momentum <code>p₀</code> and mass matrix <code>Λ</code>. The number of steps is <code>N</code> and the step size <code>ϵ</code>. </p><p>Returns <code>ΔH, xᵢ, pᵢ</code> corresponding to change in Hamiltonian, and final position and momenta. If <code>hist</code> is specified a trace of requested variables throughout each step is also returned. </p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="CMBLensing.ud_grade-Union{Tuple{P}, Tuple{∂mode}, Tuple{N}, Tuple{θ}, Tuple{T}, Tuple{Union{FlatFourier{P,T,M}, FlatMap{P,T,M}} where M,Any}} where P&lt;:Flat{N,θ,∂mode} where ∂mode where N where θ where T" href="#CMBLensing.ud_grade-Union{Tuple{P}, Tuple{∂mode}, Tuple{N}, Tuple{θ}, Tuple{T}, Tuple{Union{FlatFourier{P,T,M}, FlatMap{P,T,M}} where M,Any}} where P&lt;:Flat{N,θ,∂mode} where ∂mode where N where θ where T"><code>CMBLensing.ud_grade</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre class="language-julia"><code class="language-julia">ud_grade(f::Field, θnew, mode=:map, deconv_pixwin=true, anti_aliasing=true)</code></pre><p>Up- or down-grades field <code>f</code> to new resolution <code>θnew</code> (only in integer steps). Two modes are available specified by the <code>mode</code> argument: </p><pre class="language-none"><code class="language-none">*`:map`     : Up/downgrade by replicating/averaging pixels in map-space
*`:fourier` : Up/downgrade by extending/truncating the Fourier grid</code></pre><p>For <code>:map</code> mode, two additional options are possible. If <code>deconv_pixwin</code> is true, deconvolves the pixel window function from the downgraded map so the spectrum of the new and old maps are the same. If <code>anti_aliasing</code> is true, filters out frequencies above Nyquist prior to down-sampling. </p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="CMBLensing.δlnP_δfϕₜ" href="#CMBLensing.δlnP_δfϕₜ"><code>CMBLensing.δlnP_δfϕₜ</code></a> — <span class="docstring-category">Function</span>.</div><div><pre class="language-julia"><code class="language-julia">δlnP_δfϕₜ(t, fₜ, ϕ,                ds, Lϕ=nothing)
δlnP_δfϕₜ(t, fₜ, ϕ, θ::NamedTuple, ds, Lϕ=nothing)</code></pre><p>Compute a gradient of the log posterior probability. See <code>lnP</code> for definition of arguments of this function. </p><p>The return type is a <code>FieldTuple</code> corresponding to the <span>$(f_t,\phi)$</span> derivative.</p></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="PyPlot.plot-Tuple{Field}" href="#PyPlot.plot-Tuple{Field}"><code>PyPlot.plot</code></a> — <span class="docstring-category">Method</span>.</div><div><pre class="language-julia"><code class="language-julia">plot(f::Field; kwargs...)
plot(fs::VecOrMat{\&lt;:Field}; kwarg...)</code></pre><p>Plotting fields. </p></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="CMBLensing.ParamDependentOp" href="#CMBLensing.ParamDependentOp"><code>CMBLensing.ParamDependentOp</code></a> — <span class="docstring-category">Type</span>.</div><div><pre class="language-julia"><code class="language-julia">ParamDependentOp(recompute_function::Function)
ParamDependentOp(recompute_function!::Function, mem)</code></pre><p>Creates an ImplicitOp which depends on some parameters <span>$\theta$</span> and can be evaluated at various values of these parameters. There are two forms to construct this operator. In the first form, <code>recompute_function</code> should be a function which accepts keyword arguments for <span>$\theta$</span> and returns the operator. Each keyword must have a default value; the operator will act as if evaluated at these defaults unless it is explicitly evaluated at other parameters. In the second form, we can preallocate some memory for the results <code>mem</code>, in which case <code>recompute_function!</code> should additionally accept a single positional argument holding this memory, which should then be assigned in-place. </p><p>Example:</p><p>``julia     Cϕ₀ = Diagonal(...) # some fixed Diagonal operator     Cϕ = ParamDependentOp((;Aϕ=1)-&gt;Aϕ*Cϕ₀) # create ParamDependentOp</p><pre class="language-none"><code class="language-none">Cϕ(Aϕ=1.1) * ϕ   # Cϕ(Aϕ=1.1) is equal to 1.1*Cϕ₀
Cϕ * ϕ           # Cϕ alone will act like Cϕ(Aϕ=1) because that was the default above

# a version which preallocates the memory:
Cϕ = ParamDependentOp((mem;Aϕ=1)-&gt;(@. mem = Aϕ*Cϕ₀), similar(Cϕ₀))</code></pre><p>```</p></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="CMBLensing.RK4Solver-Tuple{Function,Any,Any,Any,Any}" href="#CMBLensing.RK4Solver-Tuple{Function,Any,Any,Any,Any}"><code>CMBLensing.RK4Solver</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p>Solve for y(t₁) with 4th order Runge-Kutta assuming dy/dt = α*F(t,y) and y(t₀) = y₀</p><p>Arguments</p><ul><li>F! : a function F!(v,t,y) which sets v=F(t,y)</li></ul></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="CMBLensing.antilensing-Union{Tuple{PowerLens{N,F}}, Tuple{F}, Tuple{N}} where F where N" href="#CMBLensing.antilensing-Union{Tuple{PowerLens{N,F}}, Tuple{F}, Tuple{N}} where F where N"><code>CMBLensing.antilensing</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p>Create from an existing PowerLens operator one that lenses by -ϕ instead. </p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="CMBLensing.beamCℓs-Tuple{}" href="#CMBLensing.beamCℓs-Tuple{}"><code>CMBLensing.beamCℓs</code></a> — <span class="docstring-category">Method</span>.</div><div><pre class="language-julia"><code class="language-julia">beamCℓs(;beamFWHM, ℓmax=8000)</code></pre><p>Compute the beam power spectrum, often called <span>$W_\ell$</span>. A map should be multiplied by <span>$\sqrt$</span> of this.</p></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="CMBLensing.conjugate_gradient" href="#CMBLensing.conjugate_gradient"><code>CMBLensing.conjugate_gradient</code></a> — <span class="docstring-category">Function</span>.</div><div><div><pre class="language-julia"><code class="language-julia">conjugate_gradient(M, A, b, x=M\b; nsteps=length(b), tol=sqrt(eps()), progress=false, callback=nothing, hist=nothing, histmod=1)</code></pre><p>Compute x = A\b (where A is positive definite) by conjugate gradient. M is the preconditioner and should approximate A, and M \ x should be fast.</p><p>The solver will stop either after <code>nsteps</code> iterations or when <code>dot(r,r)&lt;tol</code> (where <code>r=A*x-b</code> is the residual  at that step), whichever occurs first.</p><p>Info from the iterations of the solver can be returned if <code>hist</code> is specified. <code>hist</code> can be one or a tuple of:</p><ul><li><code>:i</code> - current iteration number</li><li><code>:x</code> - current solution</li><li><code>:r</code> - current residual r=A*x-b</li><li><code>:res</code> - the norm of r</li><li><code>:t</code> - the time elapsed (in seconds) since the start of the algorithm</li></ul><p><code>histmod</code> can be used to include every N-th iteration only in <code>hist</code>. </p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="CMBLensing.fftsyms-Union{Tuple{n}, Tuple{m}, Tuple{Val{m},Val{n}}} where n where m" href="#CMBLensing.fftsyms-Union{Tuple{n}, Tuple{m}, Tuple{Val{m},Val{n}}} where n where m"><code>CMBLensing.fftsyms</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p>Arguments m and n refer to the sizes of an m×n matrix (call it A) that is the output of a real FFT (thus m=n÷2+1)</p><p>Returns a tuple of (ireal, iimag, negks) where these are</p><pre class="language-none"><code class="language-none">* ireal - m×n mask corrsponding to unique real entries of A
* iimag - m×n mask corrsponding to unique imaginary entries of A
* negks - m×n matrix of giving the index into A where the negative k-vector
          is, s.t. A[i,j] = A[negks[i,j]]&#39;</code></pre></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="CMBLensing.fieldvalues-Tuple{Any}" href="#CMBLensing.fieldvalues-Tuple{Any}"><code>CMBLensing.fieldvalues</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p>Return the type&#39;s fields as a tuple</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="CMBLensing.get_term_memoizer-Tuple{Any}" href="#CMBLensing.get_term_memoizer-Tuple{Any}"><code>CMBLensing.get_term_memoizer</code></a> — <span class="docstring-category">Method</span>.</div><div><p>All of the terms in the quadratic estimate and normalization expressions look like</p><pre class="language-none"><code class="language-none">C * l[i] * l̂[j] * l̂[k] * ...</code></pre><p>where C is some field or diagonal covariance. For example, there&#39;s a term in the EB estimator that looks like:</p><pre class="language-none"><code class="language-none">(CE * (CẼ+Cn) \ d[:E])) * l[i] * l̂[j] * l̂[k]</code></pre><p>(where note that <code>l̂[j]</code> and <code>l̂[k]</code> are unit vectors, but <code>l[i]</code> is not).  The function <code>get_term_memoizer</code> returns a function <code>term</code> which could be called in the following way to compute this term:</p><pre class="language-none"><code class="language-none">term((CE * (CẼ+Cn) \ d[:E])), [i], j, k)</code></pre><p>(note that the fact that <code>l[i]</code> is not a unit vector is specified by putting the <code>[i]</code> index in brackets). </p><p>Additionally, all of these terms are symmetric in their indices, i.e. in <code>(i,j,k)</code> in this case. The <code>term</code> function is smart about this, and is memoized so that each unique set of indices is only computed once. This leads to a pretty drastic speedup for terms with many indices like those that arize in the EE and EB normalizations, and lets us write code which is both clear and fast without having to think too hard about these symmetries.</p></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="CMBLensing.rfft2vec-Tuple{AbstractArray{T,2} where T}" href="#CMBLensing.rfft2vec-Tuple{AbstractArray{T,2} where T}"><code>CMBLensing.rfft2vec</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p>Convert a matrix A which is the output of a real FFT to a real vector, keeping only unqiue real/imaginary entries of A</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="CMBLensing.unfold-Union{Tuple{AbstractArray{Complex{T},2}}, Tuple{T}} where T" href="#CMBLensing.unfold-Union{Tuple{AbstractArray{Complex{T},2}}, Tuple{T}} where T"><code>CMBLensing.unfold</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p>Convert an M×N matrix (with M=N÷2+1) which is the output a real FFT to a full N×N one via symmetries.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="CMBLensing.vec2rfft-Tuple{AbstractArray{#s13,1} where #s13&lt;:Real}" href="#CMBLensing.vec2rfft-Tuple{AbstractArray{#s13,1} where #s13&lt;:Real}"><code>CMBLensing.vec2rfft</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p>Convert a vector produced by rfft2vec back into a complex matrix.</p></div></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="CMBLensing.Σ-Tuple{Any,Any}" href="#CMBLensing.Σ-Tuple{Any,Any}"><code>CMBLensing.Σ</code></a> — <span class="docstring-category">Method</span>.</div><div><pre class="language-julia"><code class="language-julia">Σ(ϕ, ds, ::Type{L}=LenseFlow) where {L}
Σ(L::LenseOp, ds)</code></pre><p>An operator for the data covariance, Cn + P<em>M</em>B<em>L</em>Cf<em>L&#39;</em>B&#39;<em>M&#39;</em>P&#39;, which can applied and inverted.</p></div></section><footer><hr/><a class="previous" href="../05_field_basics/"><span class="direction">Previous</span><span class="title">Field Basics</span></a></footer></article></body></html>
